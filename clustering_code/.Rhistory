data("USArrests")      # Loading the data set
df <- scale(USArrests) # Scaling the data
# View the firt 3 rows of the data
head(df, n = 3)
# loeading
library(factorextra)
# loeading
library(factoextra)
# View the firt 3 rows of the data
head(df, n = 3)
# Elbow method
fviz_nbclust(df, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
fviz_nbclust(df, kmeans, nstart = 25, method = "gap_stat", nboot = 50)+
labs(subtitle = "Gap statistic method")
fviz_nbclust(df, kmeans, nstart = 25, method = "gap_stat", nboot = 100)+
labs(subtitle = "Gap statistic method")
# estimating number of clustes
library("NbClust")
nb <- NbClust(df, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
fviz_nbclust(nb)
head(df)
# Compute k-means with k = 4
set.seed(123)
km.res <- kmeans(df, 4, nstart = 25)
# Compute k-means with k = 4
set.seed(123)
km.res <- kmeans(df, 4, nstart = 25)
fviz_nbclust(df, kmeans, nstart = 25, method = "gap_stat", nboot = 200)+
labs(subtitle = "Gap statistic method")
data("USArrests")      # Loading the data set
df <- scale(USArrests) # Scaling the data
# View the firt 3 rows of the data
head(df, n = 3)
# Elbow method
fviz_nbclust(df, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
fviz_nbclust(df, kmeans, nstart = 25, method = "gap_stat", nboot = 200)+
labs(subtitle = "Gap statistic method")
getwd()
# loeading
library(factoextra)
data("USArrests")      # Loading the data set
df <- scale(USArrests) # Scaling the data
# View the firt 3 rows of the data
head(df, n = 3)
# Elbow method
fviz_nbclust(df, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
fviz_nbclust(df, kmeans, nstart = 25, method = "gap_stat", nboot = 200)+
labs(subtitle = "Gap statistic method")
# Elbow method
fviz_nbclust(df, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
fviz_nbclust(df, kmeans, nstart = 25, method = "gap_stat", nboot = 200)+
labs(subtitle = "Gap statistic method")
nb <- NbClust(df, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
library("NbClust")
nb <- NbClust(df, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
nb <- NbClust(df, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
nb$Best.nc
nb <- NbClust(df, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "kmeans")
?NbClust
set.seed(123)
# function to compute total within-cluster sum of square
wss <- function(k) {
kmeans(df, k, nstart = 10 )$tot.withinss
}
# Compute and plot wss for k = 1 to k = 15
k.values <- 1:15
# extract wss for 2-15 clusters
wss_values <- map_dbl(k.values, wss)
library(tidyverse)
library(tidyverse)
set.seed(123)
library(tidyverse)
library(tidyverse)
library(tidyverse)
library(tidyverse)
library(tidyverse)
write.csv(USArrests, '/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv')
class(data("USArrests"))
head(data("USArrests"))
class(USArrests)
check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv')
class(check_data)
head(check_data)
scale(check_data)
head
head(USArrests)
write.csv(USArrests, '/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv')
check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv')
head(check_data)
?write_csv
check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv',
col.names = c('Murder', 'Assault','UrbanPop', 'Rape'))
head(check_data)
check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv', header = TRUE)
head(check_data)
check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv', header = FALSE)
head(check_data)
check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv',
col.names = c('Murder', 'Assault','UrbanPop', 'Rape'))
head(check_data)
check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv', row.names=FALSE)
head(check_data)
# check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv',
#                        col.names = c('Murder', 'Assault','UrbanPop', 'Rape'))
#
check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv', row.names=FALSE)
head(check_data)
library(readr)
write.csv(USArrests, '/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv')
check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv')
head(check_data)
write_csv(USArrests, '/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv')
check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/CsvData/USArrests.csv')
head(check_data)
check_data <- read.csv('/Users/xbasra/Documents/myReproducibleresearch/Results/clustering_result.csv')
head(check_data)
data("USArrests")      # Loading the data set
df <- scale(USArrests) # Scaling the data
# View the firt 3 rows of the data
head(df, n = 3)
# Elbow method
fviz_nbclust(df, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# loeading
library(factoextra)
#library("NbClust")
# Elbow method
fviz_nbclust(df, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(df, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
fviz_nbclust(df, kmeans, nstart = 25, method = "gap_stat", nboot = 200)+
labs(subtitle = "Gap statistic method")
